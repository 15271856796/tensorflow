过拟合就是训练的模型太好了,基本覆盖到每个训练的数据,再加一些别的数据就会导致错误率很大很大.

预防过拟合的方法是:①增加数据量,当数据量非常大的时候就不可能覆盖到每一个数据,那么就不会发生过拟合的现象
                   ②正规化(regularization)  在过拟合中,w的变化很大,所以我们在误差的表达式上做手脚
                      因为 y=wx cost=(wx-ys)^2   那么不想w变化很大的话,就让cost=(wx-ys)^2+abs(w)
                      或者加上abs(w)^2等等,那么训练器减小误差的时候就不会让w变化很大
                    ③dropout regularization :使神经网络中的参数随机的失活